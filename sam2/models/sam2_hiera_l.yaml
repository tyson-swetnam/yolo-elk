# @package _global_

# Model
model:
  _target_: sam2.modeling.sam2_base.SAM2Base
  image_encoder:
    _target_: sam2.modeling.backbones.hieradet.Hiera
    embed_dim: 144
    num_heads: 2
    stages: [2, 6, 36, 4]
    global_att_blocks: [23, 33, 43]
    window_pos_embed_bkg_spatial_size: [7, 7]
    window_spec: [8, 4, 16, 8]
  memory_attention:
    _target_: sam2.modeling.memory_attention.MemoryAttention
    d_model: 256
    pos_enc_at_input: true
    layer:
      _target_: sam2.modeling.memory_attention.MemoryAttentionLayer
      activation: relu
      dim_feedforward: 2048
      dropout: 0.1
      pos_enc_at_attn: false
      self_attention:
        _target_: sam2.modeling.position_encoding.RoPEAttention
        rope_theta: 10000.0
        feat_sizes: [32, 32]
        embedding_dim: 256
        num_heads: 1
        downsample_rate: 1
        dropout: 0.1
      cross_attention:
        _target_: sam2.modeling.position_encoding.RoPEAttention
        rope_theta: 10000.0
        feat_sizes: [32, 32]
        embedding_dim: 256
        num_heads: 1
        downsample_rate: 1
        dropout: 0.1
        kv_in_dim: 64
    num_layers: 4
  memory_encoder:
    _target_: sam2.modeling.memory_encoder.MemoryEncoder
    out_dim: 64
    position_encoding:
      _target_: sam2.modeling.position_encoding.PositionEmbeddingSine
      num_pos_feats: 64
      normalize: true
      scale: null
      temperature: 10000
    mask_downsampler:
      _target_: sam2.modeling.memory_encoder.MaskDownSampler
      kernel_size: 4
      stride: 4
      padding: 0
      total_stride: 4
      activate_before_residual: true
    fuser:
      _target_: sam2.modeling.memory_encoder.Fuser
      layer:
        _target_: sam2.modeling.memory_encoder.CXBlock
        dim: 256
        kernel_size: 7
        padding: 3
        layer_scale_init_value: 1e-6
        use_dwconv: True
      num_layers: 2
  num_maskmem: 7
  image_size: 1024
  backbone_stride: 16
  sigmoid_scale_for_mem_enc: 1.0
  sigmoid_bias_for_mem_enc: 0.0
  use_mask_input_as_output_without_sam: false
  directly_add_no_mem_embed: false
  iou_prediction_use_sigmoid: True
  memory_temporal_stride_for_eval: 1
  add_all_frames_to_correct_as_cond: false
  sam_mask_decoder_extra_args:
    dynamic_multimask_via_stability: true
    dynamic_multimask_stability_delta: 0.05
    dynamic_multimask_stability_thresh: 0.98
  sam_prompt_embed_dim: 256
  sam_image_embedding_size: 64
  sam_mask_embed_dim: 256
  pred_obj_scores: true
  pred_obj_scores_mlp: true
  fixed_no_obj_ptr: true
  use_obj_ptrs_in_encoder: true
  max_obj_ptrs_in_encoder: 16
  use_signed_tpos_enc_to_obj_ptrs: false
  only_obj_ptrs_in_the_past_for_eval: true
