{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elk Detection and Counting Analysis\n",
    "\n",
    "This notebook analyzes the `grassland.mp4` video file using YOLO object detection to identify and count elk.\n",
    "\n",
    "## Objectives:\n",
    "- Load and analyze the grassland video\n",
    "- Use YOLO to detect animals in each frame\n",
    "- Filter detections to focus on elk/deer-like animals\n",
    "- Count and track elk throughout the video\n",
    "- Visualize results and generate summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import our YOLO detector\n",
    "from src.detection.yolo_detector import YOLODetector\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "VIDEO_PATH = \"../data/raw/grassland.mp4\"\n",
    "MODEL_PATH = \"../yolov8n.pt\"\n",
    "OUTPUT_DIR = \"../results/elk_analysis/\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Detection parameters\n",
    "CONFIDENCE_THRESHOLD = 0.3  # Lower threshold to catch more potential elk\n",
    "IOU_THRESHOLD = 0.5\n",
    "\n",
    "# COCO classes that might represent elk/deer/animals\n",
    "# Class 0: person, 15: cat, 16: dog, 17: horse, 18: sheep, 19: cow, etc.\n",
    "# We'll focus on larger mammals that could be elk\n",
    "POTENTIAL_ELK_CLASSES = [17, 18, 19, 20, 21, 22, 23]  # horse, sheep, cow, elephant, bear, zebra, giraffe\n",
    "ANIMAL_CLASS_NAMES = ['horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe']\n",
    "\n",
    "print(f\"Video path: {VIDEO_PATH}\")\n",
    "print(f\"Model path: {MODEL_PATH}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Target animal classes: {ANIMAL_CLASS_NAMES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize YOLO Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLO detector\n",
    "detector = YOLODetector(\n",
    "    model_path=MODEL_PATH,\n",
    "    device=\"auto\",\n",
    "    confidence_threshold=CONFIDENCE_THRESHOLD,\n",
    "    iou_threshold=IOU_THRESHOLD,\n",
    "    target_classes=None  # We'll filter manually to be more flexible\n",
    ")\n",
    "\n",
    "# Print model info\n",
    "model_info = detector.get_model_info()\n",
    "print(\"Model Information:\")\n",
    "for key, value in model_info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nAll available classes: {list(detector.class_names.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Analysis Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open video file\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise ValueError(f\"Could not open video file: {VIDEO_PATH}\")\n",
    "\n",
    "# Get video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "duration = frame_count / fps\n",
    "\n",
    "print(f\"Video Properties:\")\n",
    "print(f\"  Resolution: {width}x{height}\")\n",
    "print(f\"  FPS: {fps:.2f}\")\n",
    "print(f\"  Total frames: {frame_count}\")\n",
    "print(f\"  Duration: {duration:.2f} seconds\")\n",
    "\n",
    "# Sample every N frames to speed up analysis\n",
    "FRAME_SKIP = max(1, int(fps // 2))  # Sample ~2 frames per second\n",
    "print(f\"  Analyzing every {FRAME_SKIP} frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame-by-Frame Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage for results\n",
    "detection_results = []\n",
    "frame_data = []\n",
    "sample_frames = []\n",
    "\n",
    "frame_idx = 0\n",
    "analyzed_frames = 0\n",
    "\n",
    "print(\"Starting video analysis...\")\n",
    "pbar = tqdm(total=frame_count//FRAME_SKIP, desc=\"Processing frames\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Skip frames for faster processing\n",
    "    if frame_idx % FRAME_SKIP != 0:\n",
    "        frame_idx += 1\n",
    "        continue\n",
    "    \n",
    "    # Run YOLO detection\n",
    "    detections = detector.detect(frame)\n",
    "    \n",
    "    # Filter for potential elk/animal detections\n",
    "    animal_detections = []\n",
    "    for i, class_id in enumerate(detections['class_ids']):\n",
    "        class_name = detections['class_names'][i]\n",
    "        \n",
    "        # Check if this could be an elk (large mammal)\n",
    "        if (class_id in POTENTIAL_ELK_CLASSES or \n",
    "            any(animal in class_name.lower() for animal in ['horse', 'cow', 'sheep', 'deer', 'elk', 'animal'])):\n",
    "            \n",
    "            animal_detections.append({\n",
    "                'frame_idx': frame_idx,\n",
    "                'timestamp': frame_idx / fps,\n",
    "                'bbox': detections['boxes'][i],\n",
    "                'confidence': detections['scores'][i],\n",
    "                'class_id': class_id,\n",
    "                'class_name': class_name,\n",
    "                'area': (detections['boxes'][i][2] - detections['boxes'][i][0]) * \n",
    "                       (detections['boxes'][i][3] - detections['boxes'][i][1])\n",
    "            })\n",
    "    \n",
    "    # Store frame data\n",
    "    frame_info = {\n",
    "        'frame_idx': frame_idx,\n",
    "        'timestamp': frame_idx / fps,\n",
    "        'total_detections': len(detections['boxes']),\n",
    "        'animal_detections': len(animal_detections),\n",
    "        'elk_candidates': len(animal_detections)  # For now, treat all animals as potential elk\n",
    "    }\n",
    "    \n",
    "    frame_data.append(frame_info)\n",
    "    detection_results.extend(animal_detections)\n",
    "    \n",
    "    # Save some sample frames with detections for visualization\n",
    "    if len(animal_detections) > 0 and len(sample_frames) < 10:\n",
    "        sample_frames.append((frame.copy(), animal_detections, frame_idx))\n",
    "    \n",
    "    analyzed_frames += 1\n",
    "    frame_idx += 1\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "cap.release()\n",
    "\n",
    "print(f\"\\nAnalysis complete!\")\n",
    "print(f\"Analyzed {analyzed_frames} frames\")\n",
    "print(f\"Found {len(detection_results)} potential elk detections\")\n",
    "print(f\"Saved {len(sample_frames)} sample frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrames for analysis\n",
    "df_detections = pd.DataFrame(detection_results)\n",
    "df_frames = pd.DataFrame(frame_data)\n",
    "\n",
    "print(\"Detection Summary:\")\n",
    "if len(df_detections) > 0:\n",
    "    print(f\"Total detections: {len(df_detections)}\")\n",
    "    print(f\"Unique classes detected: {df_detections['class_name'].unique()}\")\n",
    "    print(f\"Average confidence: {df_detections['confidence'].mean():.3f}\")\n",
    "    print(f\"Confidence range: {df_detections['confidence'].min():.3f} - {df_detections['confidence'].max():.3f}\")\n",
    "    \n",
    "    # Class distribution\n",
    "    print(\"\\nClass distribution:\")\n",
    "    class_counts = df_detections['class_name'].value_counts()\n",
    "    for class_name, count in class_counts.items():\n",
    "        print(f\"  {class_name}: {count}\")\n",
    "else:\n",
    "    print(\"No animal detections found in the video.\")\n",
    "\n",
    "print(f\"\\nFrame Summary:\")\n",
    "print(f\"Frames with detections: {(df_frames['animal_detections'] > 0).sum()}\")\n",
    "print(f\"Max detections in single frame: {df_frames['animal_detections'].max()}\")\n",
    "print(f\"Average detections per frame: {df_frames['animal_detections'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elk Counting Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate elk count using different methods\n",
    "\n",
    "if len(df_detections) > 0:\n",
    "    # Method 1: Maximum detections in any single frame\n",
    "    max_elk_single_frame = df_frames['animal_detections'].max()\n",
    "    \n",
    "    # Method 2: Average detections across frames with detections\n",
    "    frames_with_detections = df_frames[df_frames['animal_detections'] > 0]\n",
    "    avg_elk_per_frame = frames_with_detections['animal_detections'].mean() if len(frames_with_detections) > 0 else 0\n",
    "    \n",
    "    # Method 3: Median detections in frames with detections\n",
    "    median_elk_per_frame = frames_with_detections['animal_detections'].median() if len(frames_with_detections) > 0 else 0\n",
    "    \n",
    "    # Method 4: Filter by confidence and size\n",
    "    high_conf_detections = df_detections[df_detections['confidence'] > 0.5]\n",
    "    large_detections = df_detections[df_detections['area'] > 1000]  # Larger bounding boxes\n",
    "    \n",
    "    print(\"Elk Count Estimates:\")\n",
    "    print(f\"Method 1 - Maximum in single frame: {max_elk_single_frame}\")\n",
    "    print(f\"Method 2 - Average per frame: {avg_elk_per_frame:.1f}\")\n",
    "    print(f\"Method 3 - Median per frame: {median_elk_per_frame:.1f}\")\n",
    "    print(f\"Method 4 - High confidence detections: {len(high_conf_detections)}\")\n",
    "    print(f\"Method 5 - Large detections: {len(large_detections)}\")\n",
    "    \n",
    "    # Best estimate (using maximum as it's likely the most accurate for counting individuals)\n",
    "    estimated_elk_count = max_elk_single_frame\n",
    "    print(f\"\\n*** ESTIMATED ELK COUNT: {estimated_elk_count} ***\")\n",
    "    \n",
    "else:\n",
    "    print(\"No elk detected in the video.\")\n",
    "    estimated_elk_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Detections over time\n",
    "axes[0, 0].plot(df_frames['timestamp'], df_frames['animal_detections'], 'b-', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Time (seconds)')\n",
    "axes[0, 0].set_ylabel('Number of Detections')\n",
    "axes[0, 0].set_title('Elk Detections Over Time')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Confidence distribution\n",
    "if len(df_detections) > 0:\n",
    "    axes[0, 1].hist(df_detections['confidence'], bins=20, alpha=0.7, color='green')\n",
    "    axes[0, 1].axvline(df_detections['confidence'].mean(), color='red', linestyle='--', \n",
    "                      label=f'Mean: {df_detections[\"confidence\"].mean():.3f}')\n",
    "    axes[0, 1].set_xlabel('Confidence Score')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title('Detection Confidence Distribution')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Detection area distribution\n",
    "if len(df_detections) > 0:\n",
    "    axes[1, 0].hist(df_detections['area'], bins=20, alpha=0.7, color='orange')\n",
    "    axes[1, 0].set_xlabel('Bounding Box Area (pixelsÂ²)')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].set_title('Detection Size Distribution')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Class distribution\n",
    "if len(df_detections) > 0:\n",
    "    class_counts = df_detections['class_name'].value_counts()\n",
    "    axes[1, 1].bar(range(len(class_counts)), class_counts.values, alpha=0.7, color='purple')\n",
    "    axes[1, 1].set_xticks(range(len(class_counts)))\n",
    "    axes[1, 1].set_xticklabels(class_counts.index, rotation=45)\n",
    "    axes[1, 1].set_ylabel('Count')\n",
    "    axes[1, 1].set_title('Detected Classes')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/elk_analysis_plots.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Frame Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample frames with detections\n",
    "def draw_detections(image, detections):\n",
    "    \"\"\"Draw bounding boxes on image\"\"\"\n",
    "    img_copy = image.copy()\n",
    "    \n",
    "    for det in detections:\n",
    "        bbox = det['bbox'].astype(int)\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        \n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(img_copy, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw label\n",
    "        label = f\"{det['class_name']}: {det['confidence']:.2f}\"\n",
    "        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]\n",
    "        cv2.rectangle(img_copy, (x1, y1 - label_size[1] - 10), \n",
    "                     (x1 + label_size[0], y1), (0, 255, 0), -1)\n",
    "        cv2.putText(img_copy, label, (x1, y1 - 5), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
    "    \n",
    "    return img_copy\n",
    "\n",
    "# Display sample frames\n",
    "if sample_frames:\n",
    "    n_samples = min(6, len(sample_frames))\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        frame, detections, frame_idx = sample_frames[i]\n",
    "        \n",
    "        # Draw detections\n",
    "        annotated_frame = draw_detections(frame, detections)\n",
    "        \n",
    "        # Convert BGR to RGB for matplotlib\n",
    "        annotated_frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axes[i].imshow(annotated_frame_rgb)\n",
    "        axes[i].set_title(f'Frame {frame_idx} - {len(detections)} detections')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(n_samples, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{OUTPUT_DIR}/sample_detections.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No sample frames with detections to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detailed results to CSV\n",
    "if len(df_detections) > 0:\n",
    "    df_detections.to_csv(f\"{OUTPUT_DIR}/elk_detections.csv\", index=False)\n",
    "    print(f\"Saved detailed detections to: {OUTPUT_DIR}/elk_detections.csv\")\n",
    "\n",
    "df_frames.to_csv(f\"{OUTPUT_DIR}/frame_analysis.csv\", index=False)\n",
    "print(f\"Saved frame analysis to: {OUTPUT_DIR}/frame_analysis.csv\")\n",
    "\n",
    "# Create summary report\n",
    "summary_report = {\n",
    "    'video_file': VIDEO_PATH,\n",
    "    'analysis_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'video_duration_seconds': duration,\n",
    "    'total_frames': frame_count,\n",
    "    'analyzed_frames': analyzed_frames,\n",
    "    'frames_with_detections': (df_frames['animal_detections'] > 0).sum(),\n",
    "    'total_detections': len(df_detections),\n",
    "    'estimated_elk_count': estimated_elk_count,\n",
    "    'confidence_threshold': CONFIDENCE_THRESHOLD,\n",
    "    'model_used': MODEL_PATH\n",
    "}\n",
    "\n",
    "# Save summary as JSON\n",
    "import json\n",
    "with open(f\"{OUTPUT_DIR}/analysis_summary.json\", 'w') as f:\n",
    "    json.dump(summary_report, f, indent=2)\n",
    "\n",
    "print(f\"Saved analysis summary to: {OUTPUT_DIR}/analysis_summary.json\")\n",
    "\n",
    "# Print final summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL ANALYSIS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "for key, value in summary_report.items():\n",
    "    print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
